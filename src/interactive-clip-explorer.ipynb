{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db966d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cad1c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from upyog.all import *\n",
    "\n",
    "if True:\n",
    "    import sys\n",
    "    sys.path.append(\"/home/synopsis/git/CinemaNet-Training/\")\n",
    "    sys.path.append(\"/home/synopsis/git/YOLOX-Custom/\")\n",
    "    sys.path.append(\"/home/synopsis/git/YOLO-CinemaNet/\")\n",
    "    sys.path.append(\"/home/synopsis/git/icevision/\")\n",
    "    sys.path.append(\"/home/synopsis/git/labelling-workflows/\")\n",
    "    sys.path.append(\"/home/synopsis/git/amalgam/\")\n",
    "    sys.path.append(\"/home/synopsis/git/cinemanet-multitask-classification/\")\n",
    "    sys.path.append(\"/home/synopsis/git/Synopsis.py/\")\n",
    "\n",
    "import torch\n",
    "import open_clip\n",
    "import wandb\n",
    "from cinemanet_clip.inference import *\n",
    "from cinemanet_clip.utils import *\n",
    "from training.inference import InferenceModel\n",
    "from cinemanet_clip.inference import get_top_matches\n",
    "from cinemanet_clip.inference import (\n",
    "    EVALUATION_PROMPTS, CELEBRITY_PROMPTS, PROP_PROMPTS, EMOTION_PROMPTS)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FloatSlider, Dropdown, Layout, Box, HBox, VBox, Layout, HTML\n",
    "from cinemanet.utils.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071b866",
   "metadata": {},
   "source": [
    "NOTE: These `MODEL_CONFIGS` need to be updated MANUALLY. The keys are Human Readable names that will be displayed in the UI as such.\n",
    "\n",
    "You also need to run inference separately and have the results cached. This part is a bit awkward and will be updated soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78664f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = {\n",
    "    \"ConvNeXT (256x256; Laion-Aes) - 5 Epoch\": dict(\n",
    "        arch=\"convnext_base_w\",\n",
    "        pretrained=\"laion_aesthetic_s13b_b82k\",\n",
    "#         ckpt_path=Path(\"./logs/2023_02_26-13_34_33-model_convnext_base_w-lr_0.0001-b_256-j_8-p_amp_bf16/checkpoints/epoch_5.pt\"),\n",
    "        ckpt_path=Path(\"/mnt/Data/MODELS/OPEN_CLIP/2023_02_26-13_34_33-model_convnext_base_w-lr_0.0001-b_256-j_8-p_amp_bf16/checkpoints/epoch_5.pt\"),\n",
    "    ),\n",
    "    \"ConvNeXT (256x256; Laion-2B) - 14 Epoch\": dict(\n",
    "        arch=\"convnext_base_w\",\n",
    "        pretrained=\"laion2b_s13b_b82k\",\n",
    "#         ckpt_path=Path(\"./logs/2023_02_26-13_34_33-model_convnext_base_w-lr_0.0001-b_256-j_8-p_amp_bf16/checkpoints/epoch_5.pt\"),\n",
    "        ckpt_path=Path(\"/mnt/Data/MODELS/OPEN_CLIP/2023_02_25-20_44_13-model_convnext_base_w-lr_0.0001-b_256-j_8-p_amp_bf16/checkpoints/epoch_14.pt\"),\n",
    "    ),\n",
    "    \"ViT L-14 (224x224; OpenAI)\": dict(\n",
    "        arch=\"ViT-L-14\",\n",
    "        pretrained=\"openai\",\n",
    "#         ckpt_path=Path(\"./logs/2023_02_24-14_51_33-model_ViT-L-14-lr_0.0001-b_128-j_8-p_amp_bf16/checkpoints/epoch_5.pt\"),\n",
    "        ckpt_path=Path(\"/mnt/Data/MODELS/OPEN_CLIP/2023_02_24-14_51_33-model_ViT-L-14-lr_0.0001-b_128-j_8-p_amp_bf16/checkpoints/epoch_5.pt\"),\n",
    "    )\n",
    "}\n",
    "\n",
    "MODEL_NAMES_HR = sorted(MODEL_CONFIGS.keys())\n",
    "MODEL_NAMES_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that `ckpt_path` does have all the datasets analysed\n",
    "# We're not checking that the names are consistent across all models... yet\n",
    "ckpt_path = list(MODEL_CONFIGS.values())[0]['ckpt_path']\n",
    "# ckpt_path = \"/mnt/Data/MODELS/OPEN_CLIP/2023_02_26-13_34_33-model_convnext_base_w-lr_0.0001-b_256-j_8-p_amp_bf16/checkpoints/epoch_5.pt\"\n",
    "DATASETS = [l.name for l in Path(ckpt_path).parent.parent.ls() if l.name.startswith(\"prompt\")]\n",
    "DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21b439",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoader:\n",
    "    def __init__(self):\n",
    "        self.setup_w_model_config()\n",
    "\n",
    "    def setup_w_model_config(self):\n",
    "        # Individual widgets\n",
    "        self.w_alpha = widgets.FloatSlider(value=0.0, min=0, max=1.0, step=0.25, description=\"Alpha: \")\n",
    "        self.w_model_name = Dropdown(options=MODEL_NAMES_HR)\n",
    "        self.w_load_model = widgets.Button(description=\"-- Load Model! --\")\n",
    "\n",
    "        # Events\n",
    "        self.w_load_model.on_click(lambda x: self._load_model())\n",
    "        \n",
    "        # Agg view\n",
    "        self.W_MODEL_CFG = VBox(children = [self.w_model_name, vspace(10), self.w_alpha, vspace(20), self.w_load_model])\n",
    "\n",
    "    def _load_model(self, *args):\n",
    "        logger.info(f\"Loading model!\")\n",
    "        self.inf = InferenceModelFromDisk(\n",
    "            # Args from user\n",
    "                     device = W_DEVICE.value,\n",
    "                      alpha = self.alpha,\n",
    "            # Fixed args\n",
    "                       arch = self.arch,\n",
    "                 pretrained = self.pretrained,\n",
    "                  ckpt_path = self.ckpt_path,\n",
    "            # TODO\n",
    "             path_embedding = self.path_embedding,\n",
    "            experiment_name = \"bhen ka lauda\",\n",
    "        )\n",
    "\n",
    "        # On init\n",
    "        self.df = self.inf.get_image_embeddings()\n",
    "        self.embeddings = np.stack(self.df.embedding)\n",
    "    \n",
    "    def get_top_matches(self, prompt, N, *args) -> List[PathLike]:\n",
    "        top_matches = get_top_matches(prompt, self.inf.model, self.embeddings, self.inf.tokenizer)\n",
    "        ids = [sim[1] for sim in top_matches[:N]]\n",
    "        fpaths = self.df.iloc[ids].filepath.tolist()\n",
    "        return fpaths\n",
    "\n",
    "    @property\n",
    "    def alpha(self): return self.w_alpha.value\n",
    "\n",
    "    @property\n",
    "    def arch(self): return MODEL_CONFIGS[self.w_model_name.value][\"arch\"]\n",
    "\n",
    "    @property\n",
    "    def ckpt_path(self): return MODEL_CONFIGS[self.w_model_name.value][\"ckpt_path\"]\n",
    "\n",
    "    @property\n",
    "    def base_dir(self): return self.ckpt_path.parent.parent\n",
    "    \n",
    "    @property\n",
    "    def pretrained(self): return MODEL_CONFIGS[self.w_model_name.value][\"pretrained\"]\n",
    "\n",
    "    @property\n",
    "    def path_embedding(self):\n",
    "        return list(\n",
    "            (self.base_dir / W_DATASET.value ).rglob(f\"{self.arch}--{self.pretrained}--finetuned-alpha-{self.w_alpha.value}*feather*\")\n",
    "        )[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c428cf1",
   "metadata": {},
   "source": [
    "ml = ModelLoader()\n",
    "ml.W_MODEL_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_INIT_DISPLAY = widgets.Output(layout=L_center)\n",
    "def initialise(*args):    \n",
    "    global MODELS\n",
    "    MODELS = []\n",
    "\n",
    "    for i in range(W_NUM_MODELS.value):\n",
    "        MODELS.append(ModelLoader())\n",
    "\n",
    "    cfgs = []\n",
    "    for model in MODELS:\n",
    "        cfgs.append(model.W_MODEL_CFG)\n",
    "        cfgs.append(hspace(20))\n",
    "    \n",
    "    with W_INIT_DISPLAY:\n",
    "        W_INIT_DISPLAY.clear_output()\n",
    "        display(HBox(children=cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36690eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OUT_MATCHES = widgets.HBox(children=[], layout=L_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020df648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_similarity_ui(*args):\n",
    "    def run_similarity_search(*args):\n",
    "        grids = []\n",
    "        W_OUT_MATCHES.children = grids  # Set it to empty first\n",
    "        for model in MODELS:\n",
    "            fpaths = model.get_top_matches(W_PROMPT.value, W_NUM_MATCHES.value)\n",
    "            grids.append(img_grid(fpaths, W_NCOL.value))\n",
    "            grids.append(hspace(2000))\n",
    "\n",
    "        W_OUT_MATCHES.children = grids\n",
    "\n",
    "    W_NUM_MATCHES = widgets.IntText(description=\"Num. Matches: \", value=30, layout=Layout(width=\"15%\"))\n",
    "    W_NCOL = widgets.IntText(description=\"Num. Cols: \", value=3, layout=Layout(width=\"15%\"))\n",
    "    W_PROMPT = widgets.Text(description=\"Prompt: \", value=\"An asshole holding a beer\", layout=Layout(width=\"100%\", font_size=\"20px\"))\n",
    "    W_PROMPT.style.font_size = \"18px\"\n",
    "\n",
    "    W_RUN_SIMILARITY_SEARCH = widgets.Button(description=\"ðŸš€ Run Similarity Search ðŸš€\", layout=Layout(width=\"25%\"))\n",
    "    W_RUN_SIMILARITY_SEARCH.on_click(run_similarity_search)\n",
    "\n",
    "    W_PROMPT_LAYOUT = VBox(\n",
    "        children=[\n",
    "            W_PROMPT, vspace(15), W_NUM_MATCHES, vspace(10), W_NCOL, vspace(15), W_RUN_SIMILARITY_SEARCH],\n",
    "        layout=L_center)\n",
    "    ALL = VBox(\n",
    "        children = [W_PROMPT_LAYOUT, vspace(100), W_OUT_MATCHES]\n",
    "    )\n",
    "    display(ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a19c36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W_INIT_DISPLAY.clear_output()  # Not strictly necessary here.\n",
    "\n",
    "W_DATASET = widgets.Dropdown(options=DATASETS, description=\"Dataset: \", layout=Layout(width=\"30%\"))\n",
    "W_DEVICE = widgets.Dropdown(options=[0,1,2], description=\"GPU ID: \")\n",
    "W_NUM_MODELS = widgets.IntText(description=\"Num Models: \", value=1)\n",
    "\n",
    "W_INIT_LAUNCH = widgets.Button(description=\"ðŸš€ Initialise\")\n",
    "W_INIT_SIMILARITY_UI = widgets.Button(description=\"ðŸš€ Launch Similarity UI\", layout=Layout(width=\"13%\"))\n",
    "W_INIT_SIMILARITY_UI.disabled = True\n",
    "\n",
    "W_INIT_LAUNCH.on_click(initialise)\n",
    "W_INIT_LAUNCH.on_click(lambda _: setattr(W_INIT_SIMILARITY_UI, \"disabled\", False))\n",
    "W_INIT_SIMILARITY_UI.on_click(launch_similarity_ui)\n",
    "\n",
    "W_INIT = VBox(children=[\n",
    "    W_DATASET, vspace(10), W_DEVICE, vspace(10), W_NUM_MODELS, vspace(20), W_INIT_LAUNCH,\n",
    "    vspace(50), W_INIT_DISPLAY, vspace(50), W_INIT_SIMILARITY_UI,\n",
    "], layout=L_center)\n",
    "W_INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117b7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
